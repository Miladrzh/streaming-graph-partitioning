import org.apache.spark.sql.SQLContext

val sqlContext = new SQLContext(sc)

//Souce vertex person

val knows = sqlContext.read.format("com.databricks.spark.csv").option("header", true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/person_knows_person_0_0.csv")

val knowsDF = knows.toDF("person1", "person2", "creationDate");

val email = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/person_email_emailaddress_0_0.csv")

val emailDF = email.toDF("person", "email")

val hasInterest = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/person_hasInterest_tag_0_0.csv")

val hasInterestDF = hasInterest.toDF("person", "tag")

val person_isLocatedIn = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/person_isLocatedIn_place_0_0.csv")

val person_isLocatedInDF = isLocatedIn.toDF("person", "place")

val likes_comment = sqlContext.read.format("com.databricks.spark.csv").option("header","true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/person_likes_comment_0_0.csv")

val likes_commentDF = likes_comment.toDF("person", "comment", "creationDate")

val likes_post = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/person_likes_post_0_0.csv")

val likes_postDF = likes_post.toDF("person", "post", "creationDate")

val speaks = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/person_speaks_language_0_0.csv")

val speaksDF = speaks.toDF("person", "language")

val studyAt = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/person_studyAt_organisation_0_0.csv")

val studyAtDF = studyAt.toDF("person", "organisatoin", "classYear")

val workAt = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/person_workAt_organisation_0_0.csv")

val workAtDF = workAt.toDF("person", "organisation", "workFrom")

//Source Vertex comment
val comment_hasCreator = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/comment_hasCreator_person_0_0.csv")

val comment_hasCreatorDF = hasCreator.toDF("comment", "person")

val hasTag = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/comment_hasTag_tag_0_0.csv")

val hasTagDF = hasTag.toDF("comment", "tag")

val comment_isLocatedIn = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/comment_isLocatedIn_place_0_0.csv")

val comment_isLocatedInDF = comment_isLocatedIn.toDF("comment", "place")

val replyOf_comment = sqlContext.read.format("com.databricks.spark.csv").option("header","true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/comment_replyOf_comment_0_0.csv")

val replyOf_commentDF = replyOf_comment.toDF("comment1", "comment2")

val replyOf_post = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/comment_replyOf_post_0_0.csv")

val replyOf_postDF = replyOf_post.toDF("comment", "post")

//Source Vertex forum
val containerOf = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/forum_containerOf_post_0_0.csv")

val containerOfDF = containerOf.toDF("forum", "post")

val hasMemberWithPosts = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/forum_hasMemberWithPosts_person_0_0.csv")

val hasMemberWithPostsDF = hasMemberWithPosts.toDF("forum", "person", "joinDate")

val hasMember = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/forum_hasMember_person_0_0.csv")

val hasMemberDF = hasMember.toDF("forum", "person", "joinDate")

val hasModerator = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/forum_hasModerator_person_0_0.csv")

val hasModeratorDF = hasModerator.toDF("forum", "person")

val hasTag = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/forum_hasTag_tag_0_0.csv")

val hasTagDF = hasTag.toDF("forum", "tag")

//Source Vertex organisation
val organisation_isLocatedIn = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/organisation_isLocatedIn_place_0_0.csv")

val organisation_isLocatedInDF = organisation_isLocatedIn.toDF("organisation", "place")

//Souce Vertex post
val post_hasCreator = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/post_hasCreator_person_0_0.csv")

val post_hasCreatorDF = post_hasCreator.toDF("post", "person")

val post_hasTag = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/post_hasTag_tag_0_0.csv")

val post_hasTagDF = post_hasTag.toDF("post", "tag")

val post_isLocatedIn = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/post_isLocatedIn_place_0_0.csv")

val post_isLocatedInDF = post_isLocatedIn.toDF("post", "place")

//Source Vertex place
val isPartOf = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").option("delimiter", "|").load("/Users/utakuzen/Documents/4b/URA/validation_set/place_isPartOf_place_0_0.csv")

val isPartOfDF = isPartOf.toDF("place1", "place2")





